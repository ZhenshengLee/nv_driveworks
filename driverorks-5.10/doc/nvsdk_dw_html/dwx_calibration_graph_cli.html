<!-- HTML header for doxygen 1.8.7-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<!--
 * Copyright (c) 2009-2014 NVIDIA CORPORATION.  All rights reserved.
 *
 * NVIDIA Corporation and its licensors retain all intellectual property
 * and proprietary rights in and to this software, related documentation
 * and any modifications thereto.  Any use, reproduction, disclosure or
 * distribution of this software and related documentation without an express
 * license agreement from NVIDIA Corporation is strictly prohibited.
-->
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.4"/>
<title>DriveWorks SDK Reference: Graph Calibration Tool</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="shortcut icon" href="Nvidia.ico" type="image/x-icon" />
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="reverb-search.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js"></script>
<link href="nv.css" rel="stylesheet" type="text/css" />
<link href="nvdwx.css" rel="stylesheet" type="text/css"/>
<style>
 body {
 background-position: 350px 150px;
 background-image: url(watermark.png);
 background-repeat: no-repeat;
 background-attachment: fixed;
 }
 </style>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table width="99%" border="0" cellspacing="1" cellpadding="1">
  <tbody>
    <tr valign="middle">
      <td rowspan="2" height="44" width="19%">
        <div>
            <a id="nv-logo" href="https://www.nvidia.com/"></a>
        </div>
      <td width="81%" height="44">
        <div style="text-align:right; font-weight: bold; font-size:20px"> <br/>DriveWorks SDK Reference </div>
        <div style="text-align:right">
        5.10.87 Release <br/> For Test and Development only <br/> <br/> </div>
    </td>
  </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.4 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('dwx_calibration_graph_cli.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Graph Calibration Tool </div></div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#dwx_calibration_graph_description">Description</a></li>
<li class="level1"><a href="#dwx_calibration_graph_prerequisites">Prerequisites</a></li>
<li class="level1"><a href="#dwx_calibration_graph_cli_usage">Running the Tool</a><ul><li class="level2"><a href="#dwx_calibration_graph_cli_parameters">Parameters</a></li>
</ul>
</li>
<li class="level1"><a href="#dwx_graph_cli_inputs">Calibration Input Options</a><ul><li class="level2"><a href="#dwx_graph_cli_expectedfs">Directory</a><ul><li class="level3"><a href="#dwx_graph_cli_targetdb">Target Database &lt;tt&gt;targets.json&lt;/tt&gt;</a></li>
<li class="level3"><a href="#dwx_graph_cli_special">Special Targets</a></li>
<li class="level3"><a href="#dwx_graph_cli_extra">Extra Constraints</a></li>
<li class="level3"><a href="#dwx_graph_cli_intrinsics">Intrinsics Constraints</a></li>
<li class="level3"><a href="#dwx_graph_cli_extrinsics">Extrinsic Images</a></li>
<li class="level3"><a href="#dwx_graph_cli_external">External Images</a></li>
</ul>
</li>
<li class="level2"><a href="#dwx_graph_cli_graph">Building and Calibrating the Graph</a></li>
<li class="level2"><a href="#dwx_graph_cli_json">Calibration Data JSON</a></li>
<li class="level2"><a href="#dwx_graph_cli_calibrated">A Calibrated Graph</a></li>
<li class="level2"><a href="#dwx_graph_cli_fixed_intrinsics">Fixed Intrinsics</a><ul><li class="level3"><a href="#dwx_graph_cli_fixed_intrinsics_validation">Intrinsics Validation</a></li>
</ul>
</li>
</ul>
</li>
<li class="level1"><a href="#dwx_graph_cli_outputs">Outputs</a></li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="dwx_calibration_graph_description"></a>
Description</h1>
<p >The NVIDIA<sup>&reg;</sup> DriveWorks Graph Calibration Tool optimizes the intrinsics parameters and extrinsics pose of a named set of (rigidly mounted vehicle) cameras by constructing and optimizing a calibration graph. As input it requires image and/or video recordings of a calibration scene. Please consult the <a class="el" href="dwx_camera_calibration.html">Static Camera Calibration Tutorial</a> tutorial for detailed calibration scene setup instructions, best practices on calibration recording, and insights on calibration output/result interpretation.</p>
<h1><a class="anchor" id="dwx_calibration_graph_prerequisites"></a>
Prerequisites</h1>
<p >This tool is available on the x86 Host System.</p>
<h1><a class="anchor" id="dwx_calibration_graph_cli_usage"></a>
Running the Tool</h1>
<p >Run the tool by executing: </p><pre class="fragment">/calibration-graph-cli --targetDB=[path to target database]
                       --dir=[path to directory containing calibration images]
                       --data=[path to a calibration data description json]
                       --rig=[path to a rig file]
                       --fixIntrinsics=[camera name]
                       --fixExtrinsicsRotation=[camera name]
                       --fixExtrinsicsTranslation=[camera name]
                       --graph=[path to a calibration graph json]
                       --outputDir=[path to directory]
                       --precise-validation-images=[0,1]
                       --cpu-apriltags=[0,1]
                       --logLevel=[0,1,2,3]
</pre> <h2><a class="anchor" id="dwx_calibration_graph_cli_parameters"></a>
Parameters</h2>
<pre class="fragment">--targetDB=[path to target database]
        Description: The target database to use. Automatically assigned `targets.json` when loading from `dir` structure.
                     Ignored when the [graph] parameter is supplied.

--dir=[path to directory containing calibration images]
        Description: Path to a directory with known structure to load calibration images from (see next section).
                     Any `calib-data`, `graph`, and `calibrated-graph` files in the directory will be overwritten.
                     Ignored when the [data] or [graph] parameters are supplied.

--data=[path to a calibration data description json]
        Description: Path to a calibration data description json.
                     Any graph and calibrated-graph json files in the directory will be overwritten.
                     Ignored when the [graph] parameter is supplied.

--rig=[path to a rig file]
        Description: Path to a rig file.
                     If provided, camera intrinsics and extrinsics are initialized from the rig file instead of default
                     initialized. If a camera is not listed in the provided rig file, it is default initialized instead.
                     Ignored when the [graph] parameter is supplied.

--graph=[path to a calibration graph json]
        Description: Path to a calibration graph json. Can be used to reload a previously calibrated graph and produce
                     validation images.

--outputDir=[path to directory]
        Description: Path to an existing directory to which output files are written to.

--cpu-apriltags=[0,1]
        Description: Determines the method used for AprilTag calibration target detection.
                     When set to `1`, the CPU AprilTag detector is used. When set to `0` the GPU detector is used.
                     Defaults to `1`.

--fixIntrinsics=[camera name]
        Description: Camera name for which the intrinsics model parameters won't be optimized.
                     Camera name is matched to names in the [rig] file and to the names in the input file structure. Substring matching is supported.
                     For instance: supplying `front` would fix the intrinsics of both `camera:front:wide:120fov` and 
                     `camera:front:tele:30fov'.
                     Providing multiple camera names is not supported.
                     Ignored when the [graph] parameter is supplied.

--fixExtrinsicsRotation=[camera name]
        Description: Camera name for which the rotation component of the extrinsics won't be optimized.
                     Camera name is matched to names in the [rig] file. Substring matching is supported.
                     Providing multiple camera names is not supported.
                     The [rig] parameter needs to be supplied in conjunction with this argument.
                     Ignored when the [graph] parameter is supplied.

--fixExtrinsicsTranslation=[camera name]
        Description: Camera name for which the translation component of the extrinsics won't be optimized.
                     Camera name is matched to names in the [rig] file. Substring matching is supported.
                     Providing multiple camera names is not supported.
                     The [rig] parameter needs to be supplied in conjunction with this argument.
                     Ignored when the [graph] parameter is supplied.

--precise-validation-images=[0,1]
        Description: When set to `1`, validation images are generated in .png format with fine validation overlays.
                     When set to `0`, validation images are generated in .jpg format with bolder validation overlays.
                     Defaults to `0`.

--intrinsics-validation-images=[0,1]
        Description: When set to `1`, validation images are generated for each intrinsics constraints image.
                     The intrinsics .json files need to contain the paths to the images from which the constraints have been created.
                     Also, an average background image is rendered with the overall intrinsics-validation images.
                     Defaults to `0`.

--logLevel=[0,1,2,3]
        Description: Determines the log output verbosity. Valid levels are `0`: verbose and above; `1`: debug and above;
                     `2`: warning and above; `3`: error. Level `1` is set by default.

--max-solver-iterations=[integer number &gt; 0]
                    Description: Defines the maximum number of iterations the solver is allowed to perform during optimization.
                    For Good results, this should be a big number, such the solver can reach convergence.
                    However, the bigger this number, the longer it takes until the solver aborts in case of non-convergence.
                    Defaults to `20000`.

--ftheta-reference-poly=[0,1]
                    Description: Selects whether the backward (0) or forward (1) polynomial is used as reference in the FTheta camera model.
                    Defaults to `0`.

--ftheta-poly-degree=[auto,4,5]
                    Description: Selects the polynomial degree of the reference polynomial for each FTheta camera model:
                     - `auto`: ideal polynomial degree is automatically selected based on per-camera properties
                     - `4`: unconditionally use 4th-order polynomials for all FTheta cameras
                     - `5`: unconditionally use 5th-order polynomials for all FTheta cameras

--ftheta-linear=[none,scale]
                    Description: Selects which linear transformation components of the FTheta camera model to optimize:
                    `none`: stick to identity linear term; `scale`: optimize the relative pixel scale ratio term.
                    Defaults to `none`
</pre> <h1><a class="anchor" id="dwx_graph_cli_inputs"></a>
Calibration Input Options</h1>
<h2><a class="anchor" id="dwx_graph_cli_expectedfs"></a>
Directory</h2>
<p >When using this tool with the <code>--dir</code> option, the following folder and file structure is expected to be present. The <code>extrinsics</code> and <code>intrinsics</code> folders need to contain the extrinsic and intrinsic images and/or videos of the named (vehicle) cameras to be calibrated. The <code>external</code> folder needs to contain additional images taken by an external (with respect to the calibrated vehicle) camera. These images are used to constrain the calibration scene. <code>targets.json</code> and <code>special-targets.json</code> files need to be available and contain values compatible with the to be calibrated scene targets.</p>
<div class="fragment"><div class="line">&lt;calib-data-path&gt;</div>
<div class="line">|</div>
<div class="line">|-- targets.json                   Json file containing the target database</div>
<div class="line">|                                  with the measured bar lengths.</div>
<div class="line">|</div>
<div class="line">|-- special-targets.json           Json file with ids of special targets in the scene</div>
<div class="line">|                                  (wheel targets, ground targets).</div>
<div class="line">|</div>
<div class="line">|-- extra-constraints.json         (Optional) Json file with additional constraints for the estimation.</div>
<div class="line">|</div>
<div class="line">|-- intrinsics                     Json files containing the intrinsics constraints,</div>
<div class="line">| |                                and/or an existing camera model for each camera.</div>
<div class="line">| |</div>
<div class="line">| |-- &lt;camera-0&gt;.json              NOTE: Names of the files correspond to camera names.</div>
<div class="line">| |-- ...</div>
<div class="line">| |-- &lt;camera-N&gt;.json</div>
<div class="line">| |-- external.json                Json file containing the intrinsics constraints</div>
<div class="line">|                                  for the external camera.</div>
<div class="line">|                                  If omitted, constraints are extracted</div>
<div class="line">|                                  from images under &lt;external&gt;.</div>
<div class="line">|</div>
<div class="line">|-- extrinsics                     One image from each camera looking at targets</div>
<div class="line">| |                                that define the extrinsic constraints.</div>
<div class="line">| |</div>
<div class="line">| |-- &lt;camera-0&gt;.[png/jpg]         NOTE: names of the files must match the .json</div>
<div class="line">| |-- ...                                file names from the intrinsics folder.</div>
<div class="line">| |-- &lt;camera-N&gt;.[png/jpg]</div>
<div class="line">|</div>
<div class="line">|-- external                       Images captured by external camera.</div>
<div class="line">  |</div>
<div class="line">  |-- &lt;image-0&gt;.[png/jpg/JPG]      NOTE: names of the images are irrelevant.</div>
<div class="line">  |-- ...</div>
<div class="line">  |-- &lt;image-M&gt;.[png/jpg/JPG]</div>
</div><!-- fragment --><h3><a class="anchor" id="dwx_graph_cli_targetdb"></a>
Target Database &lt;tt&gt;targets.json&lt;/tt&gt;</h3>
<p ><b>targets.json</b> is a target database file that is shipped with DriveWorks. It can be found together with the AprilTag targets under </p><pre class="fragment">data/tools/calibration/aprilTargets/targets.json
</pre><p> The target database contains a description of all AprilTag targets that can be used for extrinsic calibration. The bar length for each target in the scene must be measured, as described in <a class="el" href="dwx_camera_calibration.html#dwx_camera_calibration_prereq_targets_print_val">1.2.3 Target Print Validation</a>. It is important that these measurements are precise. The corresponding <code>barLength</code> entries in the <code>targets.json</code> <b>must be updated with the measured values</b>. This communicates the scale of the targets to the calibration tool.</p>
<h3><a class="anchor" id="dwx_graph_cli_special"></a>
Special Targets</h3>
<p >The tool employs planar AprilTag targets for both intrinsic and extrinsic calibration. The ID, layout, and metric size of these targets needs to be specified in the file <code>targets.json</code>. Some targets are considered "special". For example, targets attached to wheels, or targets laying flat on the floor that constrain the ground plane. These special targets must be declared in a separate <code>special-targets.json</code> file, with a structure similar to the following example:</p>
<div class="fragment"><div class="line">{</div>
<div class="line">    &quot;ground_targets&quot;: [99,100],</div>
<div class="line">    &quot;ignore_targets&quot;: [142],</div>
<div class="line">    &quot;wheel_targets&quot;:</div>
<div class="line">    {</div>
<div class="line">        &quot;rearLeft&quot;: 181,</div>
<div class="line">        &quot;rearRight&quot;: 182,</div>
<div class="line">        &quot;frontLeft&quot;: 180,</div>
<div class="line">        &quot;frontRight&quot;: 183</div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><h3><a class="anchor" id="dwx_graph_cli_extra"></a>
Extra Constraints</h3>
<p >Incorporating <em>prior knowledge</em> of certain pose parameters / relations can be beneficial to improve the quality of the estimation. One example is the baseline of stereo camera pairs, which is usually known accurately from sensor specifications, but which is challenging to estimate accurately as part of static calibration.</p>
<p >To incorporate such prior knowledge into the estimation, special types of extra constraints can be specified within the <code>extra-constraints.json</code> file. An example is give by</p>
<div class="fragment"><div class="line">{</div>
<div class="line">    &quot;extrinsic-constraints&quot;: [</div>
<div class="line">        {</div>
<div class="line">            &quot;type&quot;: &quot;relative-distance&quot;,</div>
<div class="line">            &quot;enableInEstimation&quot;: true,</div>
<div class="line">            &quot;enableInValidation&quot;: true,</div>
<div class="line">            &quot;sensorNameA&quot; : &quot;camera_front_tele_30fov&quot;,</div>
<div class="line">            &quot;sensorNameB&quot; : &quot;camera_front_tele_sat_30fov&quot;,</div>
<div class="line">            &quot;relativeDistanceValueMeter&quot;: 0.21,</div>
<div class="line">            &quot;relativeDistanceStdDevMeter&quot;: 0.001,</div>
<div class="line">            &quot;relativeDistanceMaxDeviationMeter&quot;: 0.005</div>
<div class="line">        },</div>
<div class="line">        {</div>
<div class="line">            &quot;type&quot;: &quot;position&quot;,</div>
<div class="line">            &quot;enableInEstimation&quot;: true,</div>
<div class="line">            &quot;enableInValidation&quot;: true,</div>
<div class="line">            &quot;sensorName&quot; : &quot;camera_front_wide_120fov&quot;,</div>
<div class="line">            &quot;positionValueMeter&quot;: [2.007, 0.0425, 1.345],</div>
<div class="line">            &quot;positionStdDevMeter&quot;: [0.01, 0.01, 0.03],</div>
<div class="line">            &quot;positionMaxDeviationMeter&quot;: [0.08, 0.08, 0.08]</div>
<div class="line">        }</div>
<div class="line">    ]</div>
<div class="line">}</div>
</div><!-- fragment --><p >Here, <code>extrinsic-constraints</code> is an array of constraints on the estimated extrinsic pose parameters. Each constraint can be enabled within the estimation (using <code>enableInEstimation</code>) and / or enabled in the result validation (using <code>enableInValidation</code>).</p>
<p ><a class="anchor" id="dwx_graph_cli_extra_constraint_types"></a> The following types of extra extrinsic constraints are currently supported:</p>
<ul>
<li><code>relative-distance</code>: defines a constraint on the <em>relative distance</em> (also called baseline) between two cameras (<code>sensorNameA</code> and <code>sensorNameB</code>), enforcing a known prior value <code>relativeDistanceValueMeter</code> (in meters) with a known standard deviation <code>relativeDistanceStdDevMeter</code>. For validation, an error is issues if the estimated relative distance between the cameras exceed <code>relativeDistanceMaxDeviationMeter</code> (in meters).</li>
<li><code>position</code>: defines a constraint on the final <em>position</em> of a sensor (<code>sensorName</code>) relative to the rig frame, enforcing a known prior value <code>positionValueMeter</code> (in meters) with a known standard deviation <code>positionStdDevMeter</code> for each position coordinate. For validation, an error is issues if the estimated position of the camera exceeds <code>positionMaxDeviationMeter</code> (in meters). As an example for the different parameter specification options, in the example specification shown above a stronger position variance for the height / z coordinate of the sensor was specified to account for additional variances, e.g., induced by potentially different vehicle suspension states (which will affect the sensor's height relative to the ground), between the provided prior values and the actual current vehicle state.</li>
</ul>
<h3><a class="anchor" id="dwx_graph_cli_intrinsics"></a>
Intrinsics Constraints</h3>
<p >There are two options to obtain the .json files with the intrinsics constraints for each camera:</p>
<h4>Intrinsics Constraints Tool</h4>
<p >Use the <a class="el" href="dwx_intrinsics_constraints.html">Intrinsics Constraints Tool</a> to extract the intrinsics constraints from a recorded video or a set of images. The tool then generates a JSON file with the camera constraints.</p>
<h4>Calibration Recorder Tool</h4>
<p >Use the <a class="el" href="dwx_calibration_recorder.html">Static Calibration Recorder Tool</a> to extract the intrinsics constraints from camera sensors that are defined in a rig .json file. This can be used to capture the constraints from a live camera stream or from recorded video. </p><dl class="section note"><dt>Note</dt><dd>This is the recommended way of getting the intrinsics constraints. The tool provides visual feedback while recording the constraints, which facilitates good coverage and distribution of constraints over the camera's field of view. </dd>
<dd>
If the camera contains a camera model in its EEPROM, the <a class="el" href="dwx_calibration_recorder.html">Static Calibration Recorder Tool</a> can read and store the model to the .json file when capturing the <a class="el" href="dwx_calibration_graph_cli.html#dwx_graph_cli_extrinsics">Extrinsic Images</a>. In that case it is not necessary to capture intrinsics constraints.</dd></dl>
<h3><a class="anchor" id="dwx_graph_cli_extrinsics"></a>
Extrinsic Images</h3>
<p >The <a class="el" href="dwx_calibration_recorder.html">Static Calibration Recorder Tool</a> can be used to obtain the images for extrinsics calibration. It provides live AprilTag detection and a camera overview while to setting up the calibration scene, and it exports the images for the extrinsics directory.</p>
<h3><a class="anchor" id="dwx_graph_cli_external"></a>
External Images</h3>
<p >These are images taken with an external photo camera. Refer to <a class="el" href="dwx_camera_calibration.html#dwx_camera_calibration_prereq_externalcam">1.1.2 External Camera</a> for the required camera properties and <a class="el" href="dwx_camera_calibration.html#dwx_camera_calibration_external_images">3.2.2 External Images</a> for more details on how these photos should be taken.</p>
<h2><a class="anchor" id="dwx_graph_cli_graph"></a>
Building and Calibrating the Graph</h2>
<p >Running the tool without arguments assumes the known file structure above. It will determine the names of the cameras from the extrinsics folder. Then it will look in the intrinsics folder for corresponding json files containing the respective cameras' intrinsic constraints. External images will be used to constrain the calibration graph via additional extrinsics constraints. If no <code>external.json</code> file with intrinsics of the external camera is provided, the external images are also used to calibrate the intrinsics of the external camera. However, this is not recommended due to worse intrinsics quality. </p><pre class="fragment">./calibration-graph-cli
</pre><h2><a class="anchor" id="dwx_graph_cli_json"></a>
Calibration Data JSON</h2>
<p >The calibration data can be explicitly specified in a json file. This file collects all intrinsics constraints as well as extrinsics and external data in a single location for convenience. The format of this json file is best understood by example. <code>./calibration-graph-cli</code> generates this file as an intermediate step. Subsequent runs can be started from this representation directly. See <code>/sdk/data/tests/tools/calibration-calibgraph/gt-scenes/quicksilver/SceneQuicksilver-v2/calib-data.json</code> for an example with 12 cameras. </p><pre class="fragment">./calibration-graph-cli --data=calib-data.json
</pre> <h2><a class="anchor" id="dwx_graph_cli_calibrated"></a>
A Calibrated Graph</h2>
<p >One of the outputs of the tool is a <code>calibrated-graph.json</code> file. This file includes all constraints (intrinsic and extrinsic) used for calibration. Running the tool with </p><pre class="fragment">./calibration-graph-cli --graph=calibrated-graph.json
</pre><p> will load the constraints from the graph, initialize the graph with the values in the file, re-run the non-linear optimization, and rewrite all the outputs.</p>
<h2><a class="anchor" id="dwx_graph_cli_fixed_intrinsics"></a>
Fixed Intrinsics</h2>
<p >The intrinsics .json files can contain a camera model, as the <a class="el" href="dwx_calibration_recorder.html">Static Calibration Recorder Tool</a> can store it either by reading from the camera's EEPROM, or it can directly calibrate with collected intrinsics itself. Alternatively, camera intrinsics can be parsed directly from an existing rig (provided with the <code>--rig</code> parameter). Intrinsics provided this way can be used with the <code>--fixIntrinsics</code> parameter, see <a class="el" href="dwx_calibration_graph_cli.html#dwx_calibration_graph_cli_parameters">Parameters</a> for usage details.</p>
<p >Intrinsics are also fixed, if an intrinsics .json file contains only a camera model, but no constraints. This is the case when reading from the camera's EEPROM and not recording any constraints additionally. In that case the stored camera model will be used for extrinsic calibration and will end up in the result.</p>
<h3><a class="anchor" id="dwx_graph_cli_fixed_intrinsics_validation"></a>
Intrinsics Validation</h3>
<p >If</p><ul>
<li>the <code>--fixIntrinsics</code> parameter is used,</li>
<li>and there are also intrinsics constraints present in the intrinsics .json file of a fixed camera,</li>
</ul>
<p >then there will still be an optimization performed that tries to match the constraints to that camera model. This optimization does not affect the calibration result. The model and the constraints match well if the reprojection errors are small (see <a class="el" href="dwx_calibration_graph_cli.html#dwx_graph_cli_outputs">Outputs</a>). This can be used to validate an existing camera model.</p>
<p >Option 1 (Existing intrinsics from rig):</p><ul>
<li>Capture constraints for a camera</li>
<li>Provide a rig file with existing intrinsics and use <code>--fixIntrinsics</code> for that camera</li>
<li>Run <code>./calibration-graph-cli --dir=&lt;calibration data&gt; --rig=&lt;rig file&gt; --fixIntrinsics=&lt;camera name&gt;</code></li>
<li>Check the <code>validation-intrinsics-&lt;camera name&gt;.jpg</code> file</li>
</ul>
<p >Option 2 (Existing intrinsics from EEPROM):</p><ul>
<li>Run <a class="el" href="dwx_calibration_recorder.html">Static Calibration Recorder Tool</a></li>
<li>Capture constraints and save them <em>without overwriting</em> the existing camera model</li>
<li>Run <code>./calibration-graph-cli --dir=&lt;calibration data&gt; --fixIntrinsics=&lt;camera name&gt;</code></li>
<li>Check the <code>validation-intrinsics-&lt;camera name&gt;.jpg</code> file</li>
</ul>
<h1><a class="anchor" id="dwx_graph_cli_outputs"></a>
Outputs</h1>
<ul>
<li>The tool outputs progress to the console. Note the warnings in yellow and errors in red. They indicate possible problems with the calibration.<br  />
<br  />
</li>
<li>The main output of the tool is the <code>calibrated-graph.json</code> file. This file contains the full calibration result in <code>.json</code> format, including all constraints, the calibrated camera models, the camera poses, and the target poses. Its format cannot be consumed by the DriveWorks SDK directly. The results can be converted with <a class="el" href="dwx_calibration_graph_to_rig.html">Calibrated Graph to Rig File Tool</a> into a valid <code>rig.json</code> file. This rig file represents the entire calibrated camera rig configuration and can be consumed by DriveWorksâ€™ dwRig module.<br  />
<br  />
</li>
<li>Intrinsic validation images (<code>validation-intrinsics-&lt;camera&gt;.jpg</code>) support the validation of a camera's intrinsic calibration. A horizontal and vertical line going through the camera's principal point visualize the calibrated angular field of view (AFoV) throughout the lens at different radii. The white concentric circles centered at the principal point indicate the calibrated AFoV at each side of the image. The white tilted cross shows the center of the image as a reference, to visualize the offset of the calibrated principal point. Blue and red points, correspond to the detected and optimized/reprojected calibration target corner points used for intrinsic calibration. Lines join corresponding detections and reprojections. Individual long lines represent outliers. Frequent long lines throughout the validation image may indicate a problem with the intrinsic calibration.<br  />
<br  />
</li>
</ul>
<p >To illustrate:</p><ul>
<li>Blue Dots = Detected.</li>
<li>Red Dots = Reprojected.</li>
<li>Short Lines (Colored blue to green) = Line joining detection and re-projection.</li>
<li>Long Lines (Colored green to orange) = Outliers are contributing less.</li>
<li>White axes indicating AFOV crossing at principal point</li>
<li>White circles representing AFoV at images sides (horizontal and vertical FoVs)</li>
</ul>
<p >There is a color legend at the bottom left that indicates the reprojection error corresponding to the line colors. It indicates the mean and range of re-projection errors. A mean re-projection error below 1pxl (ideally below 0.5pxl) with few outliers is required for adequate calibration accuracy <img src="intrinsic_validation_legend.png" alt="" class="inline" title="Intrinsic Validation Output"/>    </p>
<p >The intrinsics validation output is generated for all car cameras (<code>validation-intrinsics-&lt;camera&gt;.jpg</code>) and the external camera.</p>
<p ><img src="intrinsic_validation.jpg" alt="Intrinsic Validation Output" class="inline"/></p>
<ul>
<li>Extrinsic validation images show the image used for extrinsic calibration with overlaid results, where:<ul>
<li>Detected AprilTag targets have a green overlay.</li>
<li>Detected tags have their corner detections with the same colors as their intrinsic re-projections.</li>
<li>The ground plane is drawn as a series of green lines 1 meter apart. The lines at <code>x = 0</code> and <code>y = 0</code> are orange.</li>
</ul>
</li>
</ul>
<div class="image">
<img src="extrinsic_validation.png" alt=""/>
<div class="caption">
Extrinsic Validation Output</div></div>
    <p >The extrinsics validation output is generated for all car cameras and each external image (<code>validation-&lt;camera&gt;.jpg</code>).</p>
<ul>
<li>Extrinsic validation images (<code>validation-&lt;camera&gt;.jpg</code>) support the validation of a camera's extrinsic calibration, see <a class="el" href="dwx_camera_calibration.html#dwx_camera_calibration_tools_ext_val">4.3.3 Extrinsic Calibration Validation</a>. Reprojections of detected calibration targets are overlaid in light green. Blue and red points, respectively, correspond to the detected and optimized/reprojected calibration target corner points used for extrinsic calibration. The ground plane is drawn as a series of green lines 1m apart (lines at x=0 and y=0 are drawn in orange). Overlays should match the calibration patterns closely (at most a few pixels off).</li>
<li><p class="startli">There are 2 graphviz files written to the output directory, 'graph.dot' and 'graphCollapsedExternals.dot'. 'graph.dot' represents the graph that's being optimized in extrinsic calibration, all nodes representing things to be optimized, edges representing constraints. 'graphCollapsedExternals.dot' is a simplified version that represents external images as edges rather than nodes, this makes it easier to visually understand the relations. The '.dot' files can be converted into '.png' images by running the graphviz tool</p>
<p class="startli">neato -Tpng graph.dot &gt; graph.png </p>
</li>
</ul>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->

  <div id="nav-path" class="navpath">
    <ul>
      <li class="footer">
        Advance Information | Subject to Change |
        Prepared and Provided under NDA | Generated by NVIDIA |
        PR-08397-V5.0
      </li>
     </ul>
  </div>
</body>
</html>
