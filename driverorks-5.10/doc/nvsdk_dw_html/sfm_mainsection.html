<!-- HTML header for doxygen 1.8.7-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<!--
 * Copyright (c) 2009-2014 NVIDIA CORPORATION.  All rights reserved.
 *
 * NVIDIA Corporation and its licensors retain all intellectual property
 * and proprietary rights in and to this software, related documentation
 * and any modifications thereto.  Any use, reproduction, disclosure or
 * distribution of this software and related documentation without an express
 * license agreement from NVIDIA Corporation is strictly prohibited.
-->
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.4"/>
<title>DriveWorks SDK Reference: Structure from Motion (SFM)</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="shortcut icon" href="Nvidia.ico" type="image/x-icon" />
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="reverb-search.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js"></script>
<link href="nv.css" rel="stylesheet" type="text/css" />
<link href="nvdwx.css" rel="stylesheet" type="text/css"/>
<style>
 body {
 background-position: 350px 150px;
 background-image: url(watermark.png);
 background-repeat: no-repeat;
 background-attachment: fixed;
 }
 </style>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table width="99%" border="0" cellspacing="1" cellpadding="1">
  <tbody>
    <tr valign="middle">
      <td rowspan="2" height="44" width="19%">
        <div>
            <a id="nv-logo" href="https://www.nvidia.com/"></a>
        </div>
      <td width="81%" height="44">
        <div style="text-align:right; font-weight: bold; font-size:20px"> <br/>DriveWorks SDK Reference </div>
        <div style="text-align:right">
        5.10.87 Release <br/> For Test and Development only <br/> <br/> </div>
    </td>
  </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.4 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('sfm_mainsection.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Structure from Motion (SFM) </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1>About This Module</h1>
<p >The Structure from Motion module reconstructs the 3D structure of the scene given a moving camera rig. This is achieved by means of triangulation, e.g. geometric reasoning based on optics and multiple observations over time. The assumption made is that of a static world with a moving observer, e.g. changes in observation are only due to motion of the car and not of changes in the 3D position of the feature itself.</p>
<p >The structure is reconstructed as a point cloud and a series of rig poses, i.e. a 3D location for each tracked feature and the rotations and translations of the camera rig with respect to a fixed world reference frame. The module requires as inputs a list of tracked feature points and an initial estimate for the rig pose at each time instant. These inputs can be generated by the 2D tracker and the Egomotion module respectively.</p>
<p >The reconstructor object (<code><a class="el" href="group__reconstructor__group.html#gaaa08106190840f06c6d4355334a36238" title="Handle representing a reconstructor object.">dwReconstructorHandle_t</a></code>) provides three main functionalities: triangulating 3D points from 2D tracked features, refining the rig pose, and predicting the pixel locations of 3D points in future frames (see <code><a class="el" href="group__reconstructor__group.html#gad6515e08641b841313684a8a8b9f0c96" title="Triangulates the features of a camera from the internal feature and pose history.">dwReconstructor_triangulateFeatures()</a></code>, <code><a class="el" href="group__reconstructor__group.html#ga471d622eaf4b6827a642dbe78fb89600" title="Uses all tracked features from all cameras to estimate the current rig pose.">dwReconstructor_estimatePoseAsync()</a></code>, and <code><a class="el" href="group__reconstructor__group.html#gaf34975f50a96d12e843f9954457e6f91" title="Predicts the positions of features based on the predicted car motion.">dwReconstructor_predictFeaturePosition()</a></code>).</p>
<h2>Triangulation</h2>
<p >Triangulating points is the first step of the algorithm. 2D features must be tracked over several frames until they are observed with a wide-enough baseline to provide a stable triangulation. With the <code><a class="el" href="group__reconstructor__group.html#structdwReconstructorConfig" title="Configuration parameters for a reconstructor.">dwReconstructorConfig</a></code> structure, you specify a baseline suitable for your application.</p>
<h3>Determining When the Baseline is Wide-Enough</h3>
<p >SFM determines when there is a wide-enough baseline by waiting until several sequential frames are observed, each of which has a wide-enough baseline to provide a stable triangulation. An additional reprojection check ensures a reduced number of outliers.</p>
<p >A wide-enough baseline is not ensured for the entire rig (i.e. the minRigDistance parameter is not currently used) but the baseline is ensured for each feature being triangulated when you use a combination of minNewObservationAngleRad and minTriangulationEntries.</p>
<p >Rig distance is not a good measure for triangulation accuracy because far-away features require more distance between observations than near features. The algorithm uses the angle between optical rays as a measure instead. An observation is only added if the angle between the new observation and the observations in the history is above the threshold (minNewObservationAngleRad). Moreover, a feature is only triangulated once the number of observations is above a threshold (minTriangulationEntries). Thus, the effective minimum observation angle before triangulation can be approximated by minTriangulationEntries*minNewObservationAngleRad. This ensures a good-enough baseline for triangulation.</p>
<h3>Updating History</h3>
<p >The reconstructor object keeps a running history of the tracked features and where they have been observed at different points in time. For every frame, you must update this history by calling <code><a class="el" href="group__reconstructor__group.html#ga8b821d84fb94c2b4f24762b2ecf3ee0d" title="Updates the feature and pose history.">dwReconstructor_updateHistory()</a></code>. The algorithm calculates the observation baseline and only adds entries to the history if they contribute information for triangulation.</p>
<h3>Getting Triangulation Information</h3>
<p >After updating the history, features can be triangulated by calling dwReconstructor_triangulateFeatures. The triangulation uses the internal history accumulated over the previous frames. Only features that have accumulated enough information are triangulated. Once a feature is triangulated, if an entry in the history is detected as an outlier the status for that feature is marked as <code><a class="el" href="group__featureArray__group.html#gga41557d7183de7a8b1d351f7cb1043817aaa24301f99b0bccba0aa4045b86c03e3" title="A feature with this entry is garbage.">DW_FEATURE2D_STATUS_INVALID</a></code>. Triangulated points are returned as a 3D homogeneous point in world coordinates, where the fourth element is zero if the triangulation is invalid.</p>
<h2>Pose Refinement</h2>
<p >The SFM module requires an initial pose estimate to perform triangulation. The camera rig pose is provided as a <a class="el" href="MatrixTypes_8h.html#structdwTransformation3f" title="Specifies a 3D rigid transformation.">dwTransformation3f</a>, i.e. a 4x4 matrix composed of a 3D rotation and translation. The name of the pose argument denotes the direction of the transformation. For example, a pose called rig2World can be used to transform a point in rig coordinates to world coordinates:</p>
<div class="image">
<img src="rig_to_world.png" alt=""/>
</div>
    <p >where the points are in 3D homogeneous coordinates.</p>
<p >This pose is usually provided through odometry measurements (e.g. using the Egomotion module). However, once enough features have been triangulated this initial pose estimate can be refined by calling <code><a class="el" href="group__reconstructor__group.html#ga471d622eaf4b6827a642dbe78fb89600" title="Uses all tracked features from all cameras to estimate the current rig pose.">dwReconstructor_estimatePoseAsync()</a></code>. This function optimizes the pose by minimizing the reprojection error of 3D points with regards to the tracked features.</p>
<h2>Feature Prediction</h2>
<p >Most 2D trackers can greatly benefit from a good prediction of where a previously seen feature will be in the current frame. The SFM module can predict the position of most features given an estimation of the camera rig’s pose (see <code><a class="el" href="group__reconstructor__group.html#gaf34975f50a96d12e843f9954457e6f91" title="Predicts the positions of features based on the predicted car motion.">dwReconstructor_predictFeaturePosition()</a></code>). The module provides three types of feature prediction according to how much is known about the feature.</p>
<ul>
<li>Triangulated points are directly reprojected onto the image using the estimated rig’s pose, the rig to camera transformation, and the camera intrinsics.</li>
<li>Features without triangulation that are below the horizon are temporarily assumed to lie on the ground plane and predicted to move according to the corresponding plane-induced homography.</li>
<li>Features without triangulation that are above the horizon are temporarily assumed to be very far away from the car. Thus, only the relative rotation between the rig’s previous pose and its current pose is considered. The features are predicted to move according to the corresponding 3D rotation-induced homography.</li>
</ul>
<h1>Relevant Tutorials</h1>
<ul>
<li><a class="el" href="sfm_usecase1.html">Structure from Motion (SFM) Workflow</a></li>
</ul>
<h1>APIs</h1>
<ul>
<li><a class="el" href="group__reconstructor__group.html">Reconstructor</a> </li>
</ul>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->

  <div id="nav-path" class="navpath">
    <ul>
      <li class="footer">
        Advance Information | Subject to Change |
        Prepared and Provided under NDA | Generated by NVIDIA |
        PR-08397-V5.0
      </li>
     </ul>
  </div>
</body>
</html>
