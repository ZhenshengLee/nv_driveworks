<!-- HTML header for doxygen 1.8.7-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<!--
 * Copyright (c) 2009-2014 NVIDIA CORPORATION.  All rights reserved.
 *
 * NVIDIA Corporation and its licensors retain all intellectual property
 * and proprietary rights in and to this software, related documentation
 * and any modifications thereto.  Any use, reproduction, disclosure or
 * distribution of this software and related documentation without an express
 * license agreement from NVIDIA Corporation is strictly prohibited.
-->
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.4"/>
<title>DriveWorks SDK Reference: DNN</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="shortcut icon" href="Nvidia.ico" type="image/x-icon" />
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="reverb-search.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js"></script>
<link href="nv.css" rel="stylesheet" type="text/css" />
<link href="nvdwx.css" rel="stylesheet" type="text/css"/>
<style>
 body {
 background-position: 350px 150px;
 background-image: url(watermark.png);
 background-repeat: no-repeat;
 background-attachment: fixed;
 }
 </style>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table width="99%" border="0" cellspacing="1" cellpadding="1">
  <tbody>
    <tr valign="middle">
      <td rowspan="2" height="44" width="19%">
        <div>
            <a id="nv-logo" href="https://www.nvidia.com/"></a>
        </div>
      <td width="81%" height="44">
        <div style="text-align:right; font-weight: bold; font-size:20px"> <br/>DriveWorks SDK Reference </div>
        <div style="text-align:right">
        5.10.87 Release <br/> For Test and Development only <br/> <br/> </div>
    </td>
  </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.4 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('dnn_mainsection.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">DNN </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1>About This Module</h1>
<p >The DNN module implements functionality to run inference using deep neural networks, which were generated with an NVIDIA® TensorRT™ optimization tool.</p>
<h2>Initialization with TensorRT</h2>
<p >There are two ways of initializing DNN module with TensorRT.</p>
<ul>
<li>Use the following function to provide the path to a serialized TensorRT model file generated with TensorRT_optimization tool:</li>
</ul>
<div class="fragment"><div class="line"><a class="code hl_enumeration" href="group__core__status__group.html#ga01e41060986cf4c0d618a8923846619b">dwStatus</a> <a class="code hl_function" href="group__dnn__group.html#ga437860c89763fc8e4b74efae2e0f4cbf">dwDNN_initializeTensorRTFromFile</a>(</div>
<div class="line">    <a class="code hl_typedef" href="group__dnn__group.html#ga08a238c03a05c74a2bf3c62c275426db">dwDNNHandle_t</a> *network,</div>
<div class="line">    <span class="keyword">const</span> <span class="keywordtype">char</span> *modelFilename,</div>
<div class="line">    <span class="keyword">const</span> <a class="code hl_struct" href="group__dnn__group.html#structdwDNNPluginConfiguration">dwDNNPluginConfiguration</a> *pluginConfiguration,</div>
<div class="line">    <a class="code hl_typedef" href="group__core__context__group.html#gae81934046206143539721bbe30b08a1e">dwContextHandle_t</a> context);</div>
<div class="ttc" id="agroup__core__context__group_html_gae81934046206143539721bbe30b08a1e"><div class="ttname"><a href="group__core__context__group.html#gae81934046206143539721bbe30b08a1e">dwContextHandle_t</a></div><div class="ttdeci">struct dwContextObject * dwContextHandle_t</div><div class="ttdoc">Context handle.</div><div class="ttdef"><b>Definition:</b> <a href="Context_8h_source.html#l00083">Context.h:83</a></div></div>
<div class="ttc" id="agroup__core__status__group_html_ga01e41060986cf4c0d618a8923846619b"><div class="ttname"><a href="group__core__status__group.html#ga01e41060986cf4c0d618a8923846619b">dwStatus</a></div><div class="ttdeci">dwStatus</div><div class="ttdoc">Status definition.</div><div class="ttdef"><b>Definition:</b> <a href="Status_8h_source.html#l00173">Status.h:173</a></div></div>
<div class="ttc" id="agroup__dnn__group_html_ga08a238c03a05c74a2bf3c62c275426db"><div class="ttname"><a href="group__dnn__group.html#ga08a238c03a05c74a2bf3c62c275426db">dwDNNHandle_t</a></div><div class="ttdeci">struct dwDNNObject * dwDNNHandle_t</div><div class="ttdoc">Handles representing Deep Neural Network interface.</div><div class="ttdef"><b>Definition:</b> <a href="DNN_8h_source.html#l00062">DNN.h:62</a></div></div>
<div class="ttc" id="agroup__dnn__group_html_ga437860c89763fc8e4b74efae2e0f4cbf"><div class="ttname"><a href="group__dnn__group.html#ga437860c89763fc8e4b74efae2e0f4cbf">dwDNN_initializeTensorRTFromFile</a></div><div class="ttdeci">DW_API_PUBLIC dwStatus dwDNN_initializeTensorRTFromFile(dwDNNHandle_t *const network, const char8_t *const modelFilename, const dwDNNPluginConfiguration *const pluginConfiguration, dwProcessorType const processorType, dwContextHandle_t const context)</div><div class="ttdoc">Creates and initializes a TensorRT Network from file.</div></div>
<div class="ttc" id="agroup__dnn__group_html_structdwDNNPluginConfiguration"><div class="ttname"><a href="group__dnn__group.html#structdwDNNPluginConfiguration">dwDNNPluginConfiguration</a></div><div class="ttdoc">Specified plugin configuration.</div><div class="ttdef"><b>Definition:</b> <a href="DNN_8h_source.html#l00082">DNN.h:83</a></div></div>
</div><!-- fragment --><ul>
<li>Use the following function to provide a pointer to the memory block where the serialized TensorRT model is stored.</li>
</ul>
<div class="fragment"><div class="line"><a class="code hl_enumeration" href="group__core__status__group.html#ga01e41060986cf4c0d618a8923846619b">dwStatus</a> <a class="code hl_function" href="group__dnn__group.html#ga4593649191f89a10751511df7fd22b7f">dwDNN_initializeTensorRTFromMemory</a>(</div>
<div class="line">    <a class="code hl_typedef" href="group__dnn__group.html#ga08a238c03a05c74a2bf3c62c275426db">dwDNNHandle_t</a> *network,</div>
<div class="line">    <a class="code hl_typedef" href="group__core__context__group.html#gae81934046206143539721bbe30b08a1e">dwContextHandle_t</a> context,</div>
<div class="line">    <span class="keyword">const</span> <span class="keywordtype">char</span> *modelContent,</div>
<div class="line">    uint32_t modelContentSize,</div>
<div class="line">    <span class="keyword">const</span> <a class="code hl_struct" href="group__dnn__group.html#structdwDNNPluginConfiguration">dwDNNPluginConfiguration</a> *pluginConfiguration,</div>
<div class="line">    <a class="code hl_typedef" href="group__core__context__group.html#gae81934046206143539721bbe30b08a1e">dwContextHandle_t</a> context);</div>
<div class="ttc" id="agroup__dnn__group_html_ga4593649191f89a10751511df7fd22b7f"><div class="ttname"><a href="group__dnn__group.html#ga4593649191f89a10751511df7fd22b7f">dwDNN_initializeTensorRTFromMemory</a></div><div class="ttdeci">DW_API_PUBLIC dwStatus dwDNN_initializeTensorRTFromMemory(dwDNNHandle_t *const network, const char8_t *const modelContent, uint32_t const modelContentSize, const dwDNNPluginConfiguration *const pluginConfiguration, dwProcessorType const processorType, dwContextHandle_t const context)</div><div class="ttdoc">Creates and initializes a TensorRT Network from memory.</div></div>
</div><!-- fragment --><p >With TensorRT networks, it is possible to have custom layers. These custom layers in DriveWorks require a certain set of functions to be defined in order to be loaded and executed.</p>
<p >The definition of these functions must be provided in the form of a shared library. For more information on the function to be implemented, please see <code><a class="el" href="DNNPlugin_8h.html" title="NVIDIA DriveWorks: DNN Plugin Interface">dw/dnn/DNNPlugin.h</a></code>. For an example of plugins, please see <code>sample_dnn_plugin</code>.</p>
<h2>Inference</h2>
<p >dwDNN module offers two functions for running inference.</p>
<p >DNN models usually have one input and one output. For these kinds of models, the following function can be used for simplicity:</p>
<div class="fragment"><div class="line"><a class="code hl_enumeration" href="group__core__status__group.html#ga01e41060986cf4c0d618a8923846619b">dwStatus</a> <a class="code hl_function" href="group__dnn__group.html#ga63c2bcaae5bd45527a977398da410a57">dwDNN_inferSIO</a>(<a class="code hl_typedef" href="group__core__basictypes__group.html#ga4611b605e45ab401f02cab15c5e38715">float32_t</a> *d_output, <a class="code hl_typedef" href="group__core__basictypes__group.html#ga4611b605e45ab401f02cab15c5e38715">float32_t</a> *d_input, <a class="code hl_typedef" href="group__dnn__group.html#ga08a238c03a05c74a2bf3c62c275426db">dwDNNHandle_t</a> network);</div>
<div class="ttc" id="agroup__core__basictypes__group_html_ga4611b605e45ab401f02cab15c5e38715"><div class="ttname"><a href="group__core__basictypes__group.html#ga4611b605e45ab401f02cab15c5e38715">float32_t</a></div><div class="ttdeci">float float32_t</div><div class="ttdoc">Specifies POD types.</div><div class="ttdef"><b>Definition:</b> <a href="BasicTypes_8h_source.html#l00057">BasicTypes.h:57</a></div></div>
<div class="ttc" id="agroup__dnn__group_html_ga63c2bcaae5bd45527a977398da410a57"><div class="ttname"><a href="group__dnn__group.html#ga63c2bcaae5bd45527a977398da410a57">dwDNN_inferSIO</a></div><div class="ttdeci">DW_API_PUBLIC dwStatus dwDNN_inferSIO(float32_t *const dOutput, const float32_t *const dInput, uint32_t const batchsize, dwDNNHandle_t const network)</div><div class="ttdoc">Forwards pass from the first input blob to the first output blob (a shortcut for a single input - sin...</div></div>
</div><!-- fragment --><p >This function expects a pointer to linear device memory where the output of inference is stored, a pointer to linear device memory where the input to DNN is stored and the corresponding dwDNN handle which contains the network to run. Please note that output must be pre-allocated with the correct dimensions based on the neural network model.</p>
<p >Input to DNN is expected to have NxCxHxW layout, where N stands for batches, C for channels, H for height and W for width.</p>
<p >Moreover, dwDNN module provides a more generic function, with which it is possible to run networks with multiple inputs and/or multiple outputs:</p>
<div class="fragment"><div class="line"><a class="code hl_enumeration" href="group__core__status__group.html#ga01e41060986cf4c0d618a8923846619b">dwStatus</a> <a class="code hl_function" href="group__dnn__group.html#ga1e7f10c93a35cd1c22821871a76f957a">dwDNN_infer</a>(<a class="code hl_typedef" href="group__core__basictypes__group.html#ga4611b605e45ab401f02cab15c5e38715">float32_t</a> **d_output, <a class="code hl_typedef" href="group__core__basictypes__group.html#ga4611b605e45ab401f02cab15c5e38715">float32_t</a> **d_input, <a class="code hl_typedef" href="group__dnn__group.html#ga08a238c03a05c74a2bf3c62c275426db">dwDNNHandle_t</a> network);</div>
<div class="ttc" id="agroup__dnn__group_html_ga1e7f10c93a35cd1c22821871a76f957a"><div class="ttname"><a href="group__dnn__group.html#ga1e7f10c93a35cd1c22821871a76f957a">dwDNN_infer</a></div><div class="ttdeci">DW_API_PUBLIC dwStatus dwDNN_infer(dwDNNTensorHandle_t *const outputTensors, uint32_t const outputTensorCount, dwConstDNNTensorHandle_t *const inputTensors, uint32_t const inputTensorCount, dwDNNHandle_t const network)</div><div class="ttdoc">Runs inference pipeline on the given input.</div></div>
</div><!-- fragment --><p >This function expects an array of pointers to linear device memory blocks where the outputs of inference is stored, an array of pointers where the inputs of inference are stored and the corresponding dwDNN handle which contains the network to run.</p>
<p >In order to be sure that the inputs and outputs are given in the correct order, it is recommended to place the input and output data in their corresponding arrays at the indices based on the names of the blobs as defined in network description. The following functions return these indices:</p>
<div class="fragment"><div class="line"><a class="code hl_enumeration" href="group__core__status__group.html#ga01e41060986cf4c0d618a8923846619b">dwStatus</a> <a class="code hl_function" href="group__dnn__group.html#gaec3f0ae07d2f1230ea491c5bc71c9794">dwDNN_getInputIndex</a>(uint32_t *blobIndex,</div>
<div class="line">    <span class="keyword">const</span> <span class="keywordtype">char</span> *blobName,</div>
<div class="line">    <a class="code hl_typedef" href="group__dnn__group.html#ga08a238c03a05c74a2bf3c62c275426db">dwDNNHandle_t</a> network);</div>
<div class="line"><a class="code hl_enumeration" href="group__core__status__group.html#ga01e41060986cf4c0d618a8923846619b">dwStatus</a> <a class="code hl_function" href="group__dnn__group.html#gad8293dcdba58bc5ed80623dbaece2b48">dwDNN_getOutputIndex</a>(uint32_t *blobIndex,</div>
<div class="line">    <span class="keyword">const</span> <span class="keywordtype">char</span> *blobName,</div>
<div class="line">    <a class="code hl_typedef" href="group__dnn__group.html#ga08a238c03a05c74a2bf3c62c275426db">dwDNNHandle_t</a> network);</div>
<div class="ttc" id="agroup__dnn__group_html_gad8293dcdba58bc5ed80623dbaece2b48"><div class="ttname"><a href="group__dnn__group.html#gad8293dcdba58bc5ed80623dbaece2b48">dwDNN_getOutputIndex</a></div><div class="ttdeci">DW_API_PUBLIC dwStatus dwDNN_getOutputIndex(uint32_t *const blobIndex, const char8_t *const blobName, dwDNNHandle_t const network)</div><div class="ttdoc">Gets the index of an output blob with a given blob name.</div></div>
<div class="ttc" id="agroup__dnn__group_html_gaec3f0ae07d2f1230ea491c5bc71c9794"><div class="ttname"><a href="group__dnn__group.html#gaec3f0ae07d2f1230ea491c5bc71c9794">dwDNN_getInputIndex</a></div><div class="ttdeci">DW_API_PUBLIC dwStatus dwDNN_getInputIndex(uint32_t *const blobIndex, const char8_t *const blobName, dwDNNHandle_t const network)</div><div class="ttdoc">Gets the index of an input blob with a given blob name.</div></div>
</div><!-- fragment --><p >Furthermore, the following functions return the number of required inputs and outputs:</p>
<div class="fragment"><div class="line"><a class="code hl_enumeration" href="group__core__status__group.html#ga01e41060986cf4c0d618a8923846619b">dwStatus</a> <a class="code hl_function" href="group__dnn__group.html#ga269319d71264c471428fddfbf6445855">dwDNN_getInputBlobCount</a>(uint32_t *count, <a class="code hl_typedef" href="group__dnn__group.html#ga08a238c03a05c74a2bf3c62c275426db">dwDNNHandle_t</a> network);</div>
<div class="line"><a class="code hl_enumeration" href="group__core__status__group.html#ga01e41060986cf4c0d618a8923846619b">dwStatus</a> <a class="code hl_function" href="group__dnn__group.html#gaac4f0db98c6f751901bbec80c3986de1">dwDNN_getOutputBlobCount</a>(uint32_t *count, <a class="code hl_typedef" href="group__dnn__group.html#ga08a238c03a05c74a2bf3c62c275426db">dwDNNHandle_t</a> network);</div>
<div class="ttc" id="agroup__dnn__group_html_ga269319d71264c471428fddfbf6445855"><div class="ttname"><a href="group__dnn__group.html#ga269319d71264c471428fddfbf6445855">dwDNN_getInputBlobCount</a></div><div class="ttdeci">DW_API_PUBLIC dwStatus dwDNN_getInputBlobCount(uint32_t *const count, dwDNNHandle_t const network)</div><div class="ttdoc">Gets the input blob count.</div></div>
<div class="ttc" id="agroup__dnn__group_html_gaac4f0db98c6f751901bbec80c3986de1"><div class="ttname"><a href="group__dnn__group.html#gaac4f0db98c6f751901bbec80c3986de1">dwDNN_getOutputBlobCount</a></div><div class="ttdeci">DW_API_PUBLIC dwStatus dwDNN_getOutputBlobCount(uint32_t *const count, dwDNNHandle_t const network)</div><div class="ttdoc">Gets the output blob count.</div></div>
</div><!-- fragment --><p >In addition, dimensions of inputs and outputs are available via:</p>
<div class="fragment"><div class="line"><a class="code hl_enumeration" href="group__core__status__group.html#ga01e41060986cf4c0d618a8923846619b">dwStatus</a> <a class="code hl_function" href="group__dnn__group.html#gaaf39e646d299905aa476a214eb80d4a9">dwDNN_getInputSize</a>(<a class="code hl_struct" href="group__core__types__group.html#structdwBlobSize">dwBlobSize</a> *blobSize,</div>
<div class="line">    uint32_t blobIndex,</div>
<div class="line">    <a class="code hl_typedef" href="group__dnn__group.html#ga08a238c03a05c74a2bf3c62c275426db">dwDNNHandle_t</a> network);</div>
<div class="line"><a class="code hl_enumeration" href="group__core__status__group.html#ga01e41060986cf4c0d618a8923846619b">dwStatus</a> <a class="code hl_function" href="group__dnn__group.html#gaa5e09cada3c925610cbde90f90490b78">dwDNN_getOutputSize</a>(<a class="code hl_struct" href="group__core__types__group.html#structdwBlobSize">dwBlobSize</a> *blobSize,</div>
<div class="line">    uint32_t blobIndex,</div>
<div class="line">    <a class="code hl_typedef" href="group__dnn__group.html#ga08a238c03a05c74a2bf3c62c275426db">dwDNNHandle_t</a> network);</div>
<div class="ttc" id="agroup__core__types__group_html_structdwBlobSize"><div class="ttname"><a href="group__core__types__group.html#structdwBlobSize">dwBlobSize</a></div><div class="ttdoc">Holds blob dimensions.</div><div class="ttdef"><b>Definition:</b> <a href="Types_8h_source.html#l00256">Types.h:257</a></div></div>
<div class="ttc" id="agroup__dnn__group_html_gaa5e09cada3c925610cbde90f90490b78"><div class="ttname"><a href="group__dnn__group.html#gaa5e09cada3c925610cbde90f90490b78">dwDNN_getOutputSize</a></div><div class="ttdeci">DW_API_PUBLIC dwStatus dwDNN_getOutputSize(dwBlobSize *const blobSize, uint32_t const blobIndex, dwDNNHandle_t const network)</div><div class="ttdoc">Gets the output blob size at blobIndex.</div></div>
<div class="ttc" id="agroup__dnn__group_html_gaaf39e646d299905aa476a214eb80d4a9"><div class="ttname"><a href="group__dnn__group.html#gaaf39e646d299905aa476a214eb80d4a9">dwDNN_getInputSize</a></div><div class="ttdeci">DW_API_PUBLIC dwStatus dwDNN_getInputSize(dwBlobSize *const blobSize, uint32_t const blobIndex, dwDNNHandle_t const network)</div><div class="ttdoc">Gets the input blob size at blobIndex.</div></div>
</div><!-- fragment --><p >Inference is performed in parallel with the host, making it possible to do useful work while the DNN results are being calculated. The caller must wait for the inference to finish before reading the results.</p>
<p >By default the inference job is launched on the default CUDA stream. The simplest way to wait for the inference to finish is thus to call <code>cudaDeviceSynchronize()</code>, which waits for all pending CUDA computations to finish. For more fine-grained control the user can create a cudaStream_t using the CUDA Runtime API and pass it to the DNN with:</p>
<div class="fragment"><div class="line"><a class="code hl_enumeration" href="group__core__status__group.html#ga01e41060986cf4c0d618a8923846619b">dwStatus</a> <a class="code hl_function" href="group__dnn__group.html#ga69642ef2ee2730240e321249fe37e192">dwDNN_setCUDAStream</a>(cudaStream_t stream, <a class="code hl_typedef" href="group__dnn__group.html#ga08a238c03a05c74a2bf3c62c275426db">dwDNNHandle_t</a> network);</div>
<div class="ttc" id="agroup__dnn__group_html_ga69642ef2ee2730240e321249fe37e192"><div class="ttname"><a href="group__dnn__group.html#ga69642ef2ee2730240e321249fe37e192">dwDNN_setCUDAStream</a></div><div class="ttdeci">DW_API_PUBLIC dwStatus dwDNN_setCUDAStream(cudaStream_t const stream, dwDNNHandle_t const network)</div><div class="ttdoc">Sets the CUDA stream for infer operations.</div></div>
</div><!-- fragment --><p >After the CUDA stream is assigned to the DNN all following infer() operations are performed on the given CUDA stream. The user can then use CUDA Runtime API methods such as</p>
<div class="fragment"><div class="line">cudaError_t cudaStreamSynchronize ( cudaStream_t stream );</div>
</div><!-- fragment --><p >or</p>
<div class="fragment"><div class="line">cudaError_t cudaStreamWaitEvent ( cudaStream_t stream, cudaEvent_t event, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> flags );</div>
</div><!-- fragment --><p >to wait for the inference results. For more information about CUDA streams refer to the CUDA Runtime documentation.</p>
<h2>DNN Metadata</h2>
<p >Each DNN usually requires a specific pre-processing configuration, and it might, therefore, be necessary to include this information together with the DNN.</p>
<p >DNN Metadata contains pre-processing information relevant to the loaded network. This is not a requirement, but can be provided by the user together with the network by placing a certain json file in the same folder as the network with an additional “.json” extension.</p>
<p >For example, if the network is in path “/home/dwUser/dwApp/data/myDetector.dnn”, DNN module will look for “/home/dwUser/dwApp/data/myDetector.dnn.json” to load DNN Metadata from.</p>
<p >The json file must have the following format:</p>
<div class="fragment"><div class="line">{</div>
<div class="line">    <span class="stringliteral">&quot;dataConditionerParams&quot;</span> : {</div>
<div class="line">        <span class="stringliteral">&quot;meanValue&quot;</span> : [0.0, 0.0, 0.0],</div>
<div class="line">        <span class="stringliteral">&quot;splitPlanes&quot;</span> : <span class="keyword">true</span>,</div>
<div class="line">        <span class="stringliteral">&quot;pixelScaleCoefficient&quot;</span>: 1.0,</div>
<div class="line">        <span class="stringliteral">&quot;ignoreAspectRatio&quot;</span> : <span class="keyword">false</span>,</div>
<div class="line">        <span class="stringliteral">&quot;doPerPlaneMeanNormalization&quot;</span> : <span class="keyword">false</span></div>
<div class="line">    },</div>
<div class="line">    <span class="stringliteral">&quot;tonemapType&quot;</span> : <span class="stringliteral">&quot;none&quot;</span>,</div>
<div class="line">    <span class="stringliteral">&quot;__comment&quot;</span>: <span class="stringliteral">&quot;tonemapType can be one of {none, agtm}&quot;</span></div>
<div class="line">}</div>
</div><!-- fragment --><p >If the json file in question is not present in the same folder as the network, DNN Metadata is filled with default values. The default parameters would look like this:</p>
<div class="fragment"><div class="line">{</div>
<div class="line">    <span class="stringliteral">&quot;dataConditionerParams&quot;</span> : {</div>
<div class="line">        <span class="stringliteral">&quot;meanValue&quot;</span> : [0.0, 0.0, 0.0],</div>
<div class="line">        <span class="stringliteral">&quot;splitPlanes&quot;</span> : <span class="keyword">true</span>,</div>
<div class="line">        <span class="stringliteral">&quot;pixelScaleCoefficient&quot;</span>: 1.0,</div>
<div class="line">        <span class="stringliteral">&quot;ignoreAspectRatio&quot;</span> : <span class="keyword">false</span>,</div>
<div class="line">        <span class="stringliteral">&quot;doPerPlaneMeanNormalization&quot;</span> : <span class="keyword">false</span></div>
<div class="line">    },</div>
<div class="line">    <span class="stringliteral">&quot;tonemapType&quot;</span> : <span class="stringliteral">&quot;none&quot;</span>,</div>
<div class="line">    <span class="stringliteral">&quot;__comment&quot;</span>: <span class="stringliteral">&quot;tonemapType can be one of {none, agtm}&quot;</span></div>
<div class="line">}</div>
</div><!-- fragment --><p >Note that whether DNN Metadata is used is a decision in the application level. The Metadata can be acquired by calling:</p>
<div class="fragment"><div class="line"><a class="code hl_enumeration" href="group__core__status__group.html#ga01e41060986cf4c0d618a8923846619b">dwStatus</a> <a class="code hl_function" href="group__dnn__group.html#gaa9c305dc8918a35b56d655fa8537e312">dwDNN_getMetaData</a>(<a class="code hl_struct" href="group__dnn__group.html#structdwDNNMetaData">dwDNNMetaData</a> *metaData, <a class="code hl_typedef" href="group__dnn__group.html#ga08a238c03a05c74a2bf3c62c275426db">dwDNNHandle_t</a> network);</div>
<div class="ttc" id="agroup__dnn__group_html_gaa9c305dc8918a35b56d655fa8537e312"><div class="ttname"><a href="group__dnn__group.html#gaa9c305dc8918a35b56d655fa8537e312">dwDNN_getMetaData</a></div><div class="ttdeci">DW_API_PUBLIC dwStatus dwDNN_getMetaData(dwDNNMetaData *const metaData, dwDNNHandle_t const network)</div><div class="ttdoc">Returns the metadata for the associated network model.</div></div>
<div class="ttc" id="agroup__dnn__group_html_structdwDNNMetaData"><div class="ttname"><a href="group__dnn__group.html#structdwDNNMetaData">dwDNNMetaData</a></div><div class="ttdoc">Specifies TensorRT model header.</div><div class="ttdef"><b>Definition:</b> <a href="DNN_8h_source.html#l00067">DNN.h:68</a></div></div>
</div><!-- fragment --><h1>Relevant Tutorials</h1>
<ul>
<li><a class="el" href="dnn_usecase1.html">DNN Workflow</a></li>
<li><a class="el" href="dnn_usecase2.html">DNN Tensors</a></li>
<li><a class="el" href="dnn_usecase3.html">DNN with Safe DLA</a></li>
</ul>
<h1>APIs</h1>
<ul>
<li><a class="el" href="group__dnn__group.html">DNN Interface</a> </li>
</ul>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->

  <div id="nav-path" class="navpath">
    <ul>
      <li class="footer">
        Advance Information | Subject to Change |
        Prepared and Provided under NDA | Generated by NVIDIA |
        PR-08397-V5.0
      </li>
     </ul>
  </div>
</body>
</html>
